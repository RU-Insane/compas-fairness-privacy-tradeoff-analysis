{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import holisticai\n",
    "from holisticai.bias.mitigation.postprocessing import CalibratedEqualizedOdds, RejectOptionClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Data Loading and Baseline Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\athar\\\\OneDrive\\\\Desktop\\\\Rutgers\\\\Ethical Stat Learning\\\\Project\\\\compas-fairness-privacy-tradeoff-analysis\\\\Fairness'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_preprocessed_df = pd.read_csv(\"C:/Users/athar/OneDrive/Desktop/Rutgers/Ethical Stat Learning/Project/data/data_preprocessed_baseline.csv\",index_col=0)\n",
    "baseline_preprocessed_df = baseline_preprocessed_df.drop(['id','age_cat'],axis=1)\n",
    "#baseline_preprocessed_df['two_year_recid'] = np.where(baseline_preprocessed_df['two_year_recid'] == 1, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "protected_variables = [\"sex\", \"African-American_race\"]\n",
    "output_variable = [\"two_year_recid\"]\n",
    "\n",
    "group = [\"African-American_race\"]\n",
    "group_a = baseline_preprocessed_df[\"African-American_race\"] == 1\n",
    "group_b = baseline_preprocessed_df[\"African-American_race\"] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = baseline_preprocessed_df[output_variable]\n",
    "X = pd.get_dummies(baseline_preprocessed_df.drop(output_variable, axis=1))\n",
    "data_ = [X, y, group_a, group_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = train_test_split(*data_, test_size=0.2, shuffle=True)\n",
    "train_data = dataset[::2]\n",
    "test_data = dataset[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionnary of metrics\n",
    "metrics_dict={\n",
    "        \"Accuracy\": metrics.accuracy_score,\n",
    "        \"Balanced accuracy\": metrics.balanced_accuracy_score,\n",
    "        \"Precision\": metrics.precision_score,\n",
    "        \"Recall\": metrics.recall_score,\n",
    "        \"F1-Score\": metrics.f1_score}\n",
    "\n",
    "# efficacy metrics dataframe helper tool\n",
    "def metrics_dataframe(y_pred, y_true, metrics_dict=metrics_dict):\n",
    "    metric_list = [[pf, fn(y_true, y_pred)] for pf, fn in metrics_dict.items()]\n",
    "    return pd.DataFrame(metric_list, columns=[\"Metric\", \"Value\"]).set_index(\"Metric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement logistic regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression()),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\athar\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "X_train, y_train, group_a_train, group_b_train = train_data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# predict train set\n",
    "y_pred_train = pipeline.predict(X_train)\n",
    "y_proba_train = pipeline.predict_proba(X_train)\n",
    "\n",
    "# predict test set\n",
    "X_test, y_test, group_a_test, group_b_test = test_data\n",
    "y_pred_test = pipeline.predict(X_test)\n",
    "y_proba_test = pipeline.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Equality of opportunity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each group, of the individuals who should have a positive label (ground truth), their probability of having a positive label is the same.\n",
    "\t\n",
    "Often does not make a difference to the FPR and FRN rates, but improves equalized odds. Therefore we will not be using this technique for our purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Calibrated Equalized Odds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seeks to ensure both calibration and equalized odds. \n",
    "Calibration : Refers to the property that the model's predicted probabilities accurately reflect the true probabilities of the target variable. Equalized odds : refers to the property that the model has the same true positive rate (TPR) and false positive rate (FPR) for all protected groups.\n",
    "\t\n",
    "\t\n",
    "In other words, a calibrated equalized odds model should make predictions that are accurate and fair, regardless of the protected group of an individual. This is a challenging task, as it requires the model to balance two competing objectives: calibration and fairness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize object\n",
    "ceo = CalibratedEqualizedOdds(cost_constraint=\"fpr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<holisticai.bias.mitigation.postprocessing.calibrated_eq_odds_postprocessing.CalibratedEqualizedOdds at 0x197f8d553d0>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit it\n",
    "ceo.fit(y_train, y_proba_train, group_a_train, group_b_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform it\n",
    "d = ceo.transform(y_test, y_proba_test, group_a_test, group_b_test, 0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new predictions\n",
    "y_pred_ceo = d['y_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.654836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <td>0.639448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.681716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.459665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>0.549091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Value\n",
       "Metric                     \n",
       "Accuracy           0.654836\n",
       "Balanced accuracy  0.639448\n",
       "Precision          0.681716\n",
       "Recall             0.459665\n",
       "F1-Score           0.549091"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# efficacy\n",
    "metrics_dataframe(y_pred_ceo, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\athar\\anaconda3\\lib\\site-packages\\holisticai\\bias\\metrics\\_classification.py:172: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return sr_a / sr_b\n",
      "c:\\Users\\athar\\anaconda3\\lib\\site-packages\\holisticai\\bias\\metrics\\_classification.py:223: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return min(sr_a / sr_b, sr_b / sr_a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Reference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Statistical Parity</th>\n",
       "      <td>0.583663</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disparate Impact</th>\n",
       "      <td>inf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Four Fifths Rule</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cohen D</th>\n",
       "      <td>1.629107</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2SD Rule</th>\n",
       "      <td>23.918339</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equality of Opportunity Difference</th>\n",
       "      <td>0.760705</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive Rate Difference</th>\n",
       "      <td>0.389503</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Odds Difference</th>\n",
       "      <td>0.575104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy Difference</th>\n",
       "      <td>0.072545</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Value  Reference\n",
       "Metric                                                  \n",
       "Statistical Parity                   0.583663          0\n",
       "Disparate Impact                          inf          1\n",
       "Four Fifths Rule                     0.000000          1\n",
       "Cohen D                              1.629107          0\n",
       "2SD Rule                            23.918339          0\n",
       "Equality of Opportunity Difference   0.760705          0\n",
       "False Positive Rate Difference       0.389503          0\n",
       "Average Odds Difference              0.575104          0\n",
       "Accuracy Difference                  0.072545          0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from holisticai.bias.metrics import classification_bias_metrics\n",
    "classification_bias_metrics(group_a_test, group_b_test, y_pred_ceo, y_test, metric_type='both')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Reject Option Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reject Option Classification (ROC) is a classification technique in machine learning that allows the classifier to abstain from making a prediction when the confidence in its prediction is low. This is in contrast to traditional classification, where the classifier is forced to make a prediction for every input instance, even if the classifier is uncertain about the true label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "ROC is particularly useful in situations where making an incorrect decision can have significant consequences, such as in medical diagnosis or fraud detection. By allowing the classifier to abstain from making a prediction when it is uncertain, ROC can help to reduce the risk of making errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\athar\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "baseline_preprocessed_df['two_year_recid'] = np.where(baseline_preprocessed_df['two_year_recid'] == 1, 0, 1)\n",
    "\n",
    "y = baseline_preprocessed_df[output_variable]\n",
    "X = pd.get_dummies(baseline_preprocessed_df.drop(output_variable, axis=1))\n",
    "data_ = [X, y, group_a, group_b]\n",
    "\n",
    "dataset = train_test_split(*data_, test_size=0.2, shuffle=True)\n",
    "train_data = dataset[::2]\n",
    "test_data = dataset[1::2]\n",
    "\n",
    "\n",
    "# train\n",
    "X_train, y_train, group_a_train, group_b_train = train_data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# predict train set\n",
    "y_pred_train = pipeline.predict(X_train)\n",
    "y_proba_train = pipeline.predict_proba(X_train)\n",
    "\n",
    "# predict test set\n",
    "X_test, y_test, group_a_test, group_b_test = test_data\n",
    "y_pred_test = pipeline.predict(X_test)\n",
    "y_proba_test = pipeline.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "roc = RejectOptionClassification(metric_name=\"Statistical parity difference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<holisticai.bias.mitigation.postprocessing.reject_option_classification.RejectOptionClassification at 0x197f7622f40>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit it\n",
    "roc.fit(y_train, y_proba_train, group_a_train, group_b_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y_pred': array([ True, False,  True, ...,  True,  True, False]),\n",
       " 'y_score': array([0.75048265, 0.55095153, 0.68877118, ..., 0.67994792, 0.64927536,\n",
       "        0.61921092])}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform it\n",
    "d = roc.transform(y_test, y_proba_test, group_a_test, group_b_test)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, ...,  True,  True, False])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new predictions\n",
    "y_pred = d['y_pred']\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.677801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <td>0.679840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.728291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.659062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>0.691949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Value\n",
       "Metric                     \n",
       "Accuracy           0.677801\n",
       "Balanced accuracy  0.679840\n",
       "Precision          0.728291\n",
       "Recall             0.659062\n",
       "F1-Score           0.691949"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# efficacy\n",
    "metrics_dataframe(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Reference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Statistical Parity</th>\n",
       "      <td>0.027479</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Disparate Impact</th>\n",
       "      <td>1.056951</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Four Fifths Rule</th>\n",
       "      <td>0.946117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cohen D</th>\n",
       "      <td>0.054981</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2SD Rule</th>\n",
       "      <td>1.040637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equality of Opportunity Difference</th>\n",
       "      <td>0.097446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive Rate Difference</th>\n",
       "      <td>0.037807</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Odds Difference</th>\n",
       "      <td>0.067626</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy Difference</th>\n",
       "      <td>0.041760</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Value  Reference\n",
       "Metric                                                 \n",
       "Statistical Parity                  0.027479          0\n",
       "Disparate Impact                    1.056951          1\n",
       "Four Fifths Rule                    0.946117          1\n",
       "Cohen D                             0.054981          0\n",
       "2SD Rule                            1.040637          0\n",
       "Equality of Opportunity Difference  0.097446          0\n",
       "False Positive Rate Difference      0.037807          0\n",
       "Average Odds Difference             0.067626          0\n",
       "Accuracy Difference                 0.041760          0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bias metrics\n",
    "classification_bias_metrics(group_a_test, group_b_test, y_pred, y_test, metric_type='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = baseline_preprocessed_df[output_variable]\n",
    "\n",
    "X = pd.get_dummies(baseline_preprocessed_df.drop(output_variable, axis=1))\n",
    "data_ = [X, y, group_a, group_b]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
